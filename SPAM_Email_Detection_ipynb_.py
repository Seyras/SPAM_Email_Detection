# -*- coding: utf-8 -*-
"""Копия блокнота "SPAM_Email_Detection.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EF-YEHE1UaW8RdxYOqWuVjT7w6QYIsFo
"""

import numpy as np
import pandas as pd
import spacy
import re
import matplotlib.pyplot as plt
from sklearn.utils import shuffle

spam_words = ['life enhancement', 'win lottery', 'earn money', 'bonus guaranteed', 'free', 'click', 'limited time', 'specia offer', 'winner',
      'amazing prize', 'subscripe and get cash now!', 'win gift', 'award', 'bonus for you', 'trial', 'sample', 'pills', 'medication', 'without prescription',
      'formula', 'deal', 'bargain', 'discount', 'savings', 'guaranteed investment', 'become expert mortgage', 'finance', 'zero interest loan', 'credit',
      'sex near', 'dating', 'for singles', 'hot!', 'beautiful girls', 'become rich', 'luxury life', 'opportunity', 'job', 'employment',
      'increase your income', 'work', 'urgent', 'alert', 'notification', 'accounts', 'banking', 'verification', 'security',
      'identity', 'not scam', 'fraud', 'risk-free', 'promise', 'results', 'male', 'female', 'men', 'meet women', 'pictures',
      'photos', 'images', 'satisfaction', 'relationships', 'want romance', 'make love', 'intimate', 'adult', 'sexy', 'XXX',
      'claim', 'win', 'won', 'winning', 'prized', 'rewards', 'gift', 'present', 'special', 'happy', 'valued',
      'customer', 'congratulations you have won!', 'lucky you !', 'you will have immediate profit ', 'unlimited', 'billion', 'jackpot', 'profit', 'earnings',
      'inheritance', 'windfall', 'buyer', 'shopper', 'purchase now', 'buyer', 'free shipping', 'free delivery','bonus'
      "100% free", "Act now", "Ad", "Affordable", "Apply now", "Best price", "Big bucks",
      "Billion", "Call now", "Cancel at any time", "Certified", "Cheap", "Click below",
      "Click here", "Congratulations", "Credit card offers", "Cure", "Dear friend",
      "Discount", "Double your income", "Earn money", "Easy money", "Eliminate bad credit",
      "Exclusive deal", "Fantastic", "Fast cash", "Financial freedom", "Free consultation",
      "Free gift", "Free info", "Free membership", "Free preview", "Free quote",
      "Free trial", "Full refund", "Get it now", "Get out of debt", "Guarantee",
      "Guaranteed", "Increase sales", "Increase traffic", "Incredible deal", "Instant",
      "Limited time", "Lose weight", "Lowest price", "Luxury", "Make money",
      "Million dollars", "Miracle", "Money back", "No cost", "No credit check",
      "No fees", "No hidden costs", "No hidden fees", "No obligation",
      "No purchase necessary", "Offer expires", "Once in a lifetime", "One time",
      "Only", "Outstanding value", "Promise", "Pure profit", "Risk-free",
      "Satisfaction guaranteed", "Save big", "Save cash", "Save money",
      "Special promotion", "Super deal", "Take action", "This won’t last",
      "Unlimited", "Urgent", "Visit our website", "Win", "Winner", "Winning",
      "Work from home"
]

# 1 - spam, 0 - not spam
data_set = [
    ("Win a special prize with just one click!",1),
    ("We will have a meeting at 3 PM today.",0),
    ("Guaranteed investment returns for a limited time.",1),
    ("Please read the attached document carefully.",0),
    ("Free trial of the newest medication without prescription.",1),
    ("She loves playing the piano in her free time.",0),
    ("Earn money from home with this amazing opportunity.",1),
    ("He received an award for his excellent performance.",0),
    ("Click here to claim your bonus and double your income.",1),
    ("The weather is beautiful, let's go for a walk.",0),
    ("Exclusive offer: 100% free access to premium services.",1),
    ("She has been selected for the national team.",0),
    ("Urgent notification: You've been selected for a gift!",1),
    ("Do not forget to submit your project by Friday.",0),
    ("Get your risk-free trial of miracle pills now.",1),
    ("They are planning to travel to Europe next summer.",0),
    ("Increase your income instantly with our unique formula.",1),
    ("The cat sat on the mat quietly.",0),
    ("Join today and win a luxury life with zero interest loans.",1),
    ("He cooked a delicious meal for his friends.",0),
    ("Act now to get your special promotion.",1),
    ("He recently published a novel that became a bestseller.",0),
    ("Sign up free and receive exclusive rewards.",1),
    ("She enjoys gardening in her spare time.",0),
    ("Don't miss out on this limited-time offer.",1),
    ("They organized a charity event for the local community.",0),
    ("Click here to unlock your amazing prize.",1),
    ("He received a scholarship for his academic excellence.",0),
    ("Earn extra cash with zero investment required.",1),
    ("The sunset over the ocean was breathtaking.",0)

]

data_set = shuffle(data_set)

# Loading spaCy model
nlp = spacy.load("en_core_web_sm")

# We write a function for cleaning text
def preprocess_text(text):
    text = text.lower()
    doc = nlp(text)
    lemmatized_text = " ".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])
    lemmatized_text = re.sub(r'[^\w\s]', '', lemmatized_text)
    lemmatized_text = re.sub(r'\s+', ' ', lemmatized_text).strip()
    return lemmatized_text

df = pd.DataFrame(data_set, columns=['message', 'label']) # Creating the DataFrame 'df' from 'data_set'

# We apply the function to messages
df['cleaned_message'] = df['message'].apply(preprocess_text)

df['label'].value_counts().plot(kind='bar', color=['blue', 'red'])
plt.title('Number of spam and non-spam offers in dataset')
plt.ylabel('Amount')
plt.show()

print(df[['message', 'cleaned_message']].head())

from sklearn.feature_extraction.text import TfidfVectorizer

# Initializing the vectorizer
vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=5000)

# Converting text to a numerical matrix
X = vectorizer.fit_transform(df['cleaned_message'])

# Spam or not spam
y = df['label']

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.preprocessing import MaxAbsScaler
from sklearn.model_selection import cross_val_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Data normalization
scaler = MaxAbsScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Model creation and training
model = LogisticRegression(class_weight='balanced')
model.fit(X_train, y_train)



scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
plt.plot(range(1, 6), scores, marker='o', linestyle='-', color='b')
plt.title('Cross-validation Accuracy Scores')
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()
print(f"Accuracy: {scores.mean()}")

new_messages = [""]

cleaned_messages = [preprocess_text(msg) for msg in new_messages]

X_new = vectorizer.transform(cleaned_messages)
predictions = model.predict(X_new)


print("Predictions:", predictions)